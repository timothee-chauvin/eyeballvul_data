{
  "id": "CVE-2024-42477",
  "published": "2024-08-12T15:15:21",
  "modified": "2024-10-08T04:27:24.153899",
  "details": "llama.cpp provides LLM inference in C/C++. The unsafe `type` member in the `rpc_tensor` structure can cause `global-buffer-overflow`. This vulnerability may lead to memory data leakage. The vulnerability is fixed in b3561.",
  "severity": [
    {
      "type": "CVSS_V3",
      "score": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H"
    }
  ],
  "repo_url": "https://github.com/ggerganov/llama.cpp",
  "cwes": [],
  "commits": [
    "940362224d20e35f13aa5fd34a0d937ae57bdf7d"
  ]
}
