{
  "id": "CVE-2025-53630",
  "published": "2025-07-10T20:15:27",
  "modified": "2025-07-29T11:24:58.906604",
  "details": "llama.cpp is an inference of several LLM models in C/C++. Integer Overflow in the gguf_init_from_file_impl function in ggml/src/gguf.cpp can lead to Heap Out-of-Bounds Read/Write. This vulnerability is fixed in commit 26a48ad699d50b6268900062661bd22f3e792579.",
  "repo_url": "https://github.com/ggml-org/llama.cpp",
  "cwes": [],
  "commits": [
    "0c4d489e29e53589bf13a801fe7c94b7b546d8f6"
  ]
}
