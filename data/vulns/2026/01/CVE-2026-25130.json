{
  "id": "CVE-2026-25130",
  "published": "2026-01-30T20:15:51.772000",
  "modified": "2026-02-05T20:48:05.731279",
  "details": "Cybersecurity AI (CAI) is a framework for AI Security. In versions up to and including 0.5.10, the CAI (Cybersecurity AI) framework contains multiple argument injection vulnerabilities in its function tools. User-controlled input is passed directly to shell commands via `subprocess.Popen()` with `shell=True`, allowing attackers to execute arbitrary commands on the host system. The `find_file()` tool executes without requiring user approval because find is considered a \"safe\" pre-approved command. This means an attacker can achieve Remote Code Execution (RCE) by injecting malicious arguments (like -exec) into the args parameter, completely bypassing any human-in-the-loop safety mechanisms. Commit e22a1220f764e2d7cf9da6d6144926f53ca01cde contains a fix.",
  "summary": "Cybersecurity AI vulnerable to command Injection through argument injection in find_file Agent tool",
  "severity": [
    {
      "type": "CVSS_V3",
      "score": "CVSS:3.1/AV:N/AC:L/PR:N/UI:R/S:C/C:H/I:H/A:H"
    }
  ],
  "repo_url": "https://github.com/aliasrobotics/cai",
  "cwes": [],
  "commits": [
    "96aff0d7d9e3ca9b11d2677479db50ed4da6cbb1"
  ]
}
