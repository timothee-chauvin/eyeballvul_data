{
  "id": "CVE-2023-29374",
  "published": "2023-04-05T02:15:37",
  "modified": "2023-11-29T10:06:17.293186",
  "details": "In LangChain through 0.0.131, the LLMMathChain chain allows prompt injection attacks that can execute arbitrary code via the Python exec method.",
  "severity": [
    {
      "type": "CVSS_V3",
      "score": "CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:H/I:H/A:H"
    }
  ],
  "repo_url": "https://github.com/hwchase17/langchain",
  "cwes": [],
  "commits": [
    "08400f554215e98f886d4f4a1b98d6029c4b2a02"
  ]
}
